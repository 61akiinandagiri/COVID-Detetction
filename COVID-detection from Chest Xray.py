# -*- coding: utf-8 -*-
"""Final_Chest_Results.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vc6o34TfdZjj9E_lpRdLS3veLf1MZqmq
"""

#Importing the required libraries
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

#Defining the data path for covid and non-covid from google drive 
covid_path = '/content/drive/My Drive/data/chest/Chest_COVID'
noncovid_path = '/content/drive/My Drive/data/chest/Chest_NonCOVID'

# Use glob to grab images from path .jpg or jpeg
from glob import glob
covid_files = glob(covid_path + '/*')
noncovid_files = glob(noncovid_path + '/*')

# Declaring an empty array for images and labels along with the image size 
covid_images=[]
noncovid_images=[]

covid_labels = []
noncovid_labels = []

IMAGE_SIZE = [224, 224]

"""## **`Data Pre-processing`**"""

#Pre-processing of raw images using cv2 library and appeding labels for covid and non-covid images 
import cv2 

for i in range(len(covid_files)):
  image = cv2.imread(covid_files[i])
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  image = cv2.resize(image,(224,224))
  covid_images.append(image)
  covid_labels.append('Chest_COVID')
for i in range(len(noncovid_files)):
  image = cv2.imread(noncovid_files[i])
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  image = cv2.resize(image,(224,224))
  noncovid_images.append(image)
  noncovid_labels.append('Chest_NonCOVID')

#Displaying some pre-processed sample images for covid and non-covid pateints
def plot_images(images, title):
  nrows, ncols = 5, 8
  figsize = [10, 6]
  fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))
  for i, axi in enumerate(ax.flat):
    axi.imshow(images[i])
    axi.set_axis_off()
  plt.suptitle(title, fontsize=24)
  plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])
  plt.show()
plot_images(covid_images, 'Pateint diagnosed with COVID-19: Chest X-ray')
plot_images(noncovid_images, 'Pateint not diagnosed with COVID-19: Chest X-ray')

#Normalizing the images to bring it on a same scale 
covid_images = np.array(covid_images)/ 255
noncovid_images = np.array(noncovid_images) / 255

"""## **Data Preparation**"""

from sklearn.model_selection import train_test_split 
from tensorflow.keras.utils import to_categorical

#Splitting of data into traning and testing 
covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(covid_images, covid_labels, test_size=0.2)

noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(noncovid_images, noncovid_labels, test_size=0.2)

#Here concatenating of covid and non-covid images into a single variable is carried out
X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)
X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)
y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)
y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)

from sklearn.preprocessing import LabelBinarizer #Label encoding for covid and non-covid labels
# Label encoding for target variable 
y_train = LabelBinarizer().fit_transform(y_train)
y_train = to_categorical(y_train)

y_test = LabelBinarizer().fit_transform(y_test)
y_test = to_categorical(y_test)

# 0 --> Non-covid
# 1 --> Covid

#Data augmentation is done to increase the samples for traning the proposed models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_aug = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

"""## **Model Building**"""

#Importing the required libraries from keras for implementing Transfer Learning model like Xception, Resnet and VGG19
from __future__ import print_function, division
from builtins import range, input

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, AveragePooling2D, Dropout
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image

"""## **ResNet 50 Transfer Learning model**"""

#Building the resnet transfer learning model 
res = ResNet50(weights="imagenet", include_top=False,input_tensor=Input(shape=(224, 224,3)))

outputs = res.output
outputs = Flatten(name="flatten")(outputs)
outputs = Dropout(0.5)(outputs)
outputs = Dense(2, activation="softmax")(outputs)

model = Model(inputs=res.input, outputs=outputs)

for layer in res.layers:
    layer.trainable = False # As we are using the transfer learning weights and not traning our model, the trainable parameter is False

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

#Fitting the model on augmented x_train data
history = model.fit(train_aug.flow(X_train, y_train, batch_size=32),
                    validation_data=(X_test, y_test),validation_steps=len(X_test) / 32,
                    steps_per_epoch=len(X_train) / 32,
                    epochs=20)

#Saving the model and weights for future use
model.save('resnet_chest.h5')
model.save_weights('resnetweights_chest.hdf5')

model = load_model('resnet_chest.h5')
#Predicting the labels for testing images
y_pred = model.predict(X_test, batch_size= 32)

prediction=y_pred[0:10]
for index, probability in enumerate(prediction):
  if probability[1] > 0.5:
        plt.title('%.2f' % (probability[1]*100) + '% COVID')
  else:
        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')
  plt.imshow(X_test[index])
  plt.show()

# Convert to Binary classes
y_pred_bin = np.argmax(y_pred, axis=1)
y_test_bin = np.argmax(y_test, axis=1)

from sklearn.metrics import confusion_matrix, roc_curve
fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)
plt.plot(fpr, tpr)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.rcParams['font.size'] = 12
plt.title('ROC curve for our model')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)

#defining a fucntion to generate a heatmap confusion matrix for predicted values 
def plot_confusion_matrix(normalize):
  classes = ['COVID','NonCOVID']
  tick_marks = [0.5,1.5]
  cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)
  sns.heatmap(cn,cmap='plasma',annot=True)
  plt.xticks(tick_marks, classes)
  plt.yticks(tick_marks, classes)
  plt.title('Confusion Matrix')
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()

#Plotting the confusion matrix with normalized and non-normalized outputs
print('Confusion Matrix without Normalization')
plot_confusion_matrix(normalize=None)

print('Confusion Matrix with Normalized Values')
plot_confusion_matrix(normalize='true')

#Evaluating the classification report 
from sklearn.metrics import classification_report
print(classification_report(y_test_bin, y_pred_bin))

#Plot for model accuracy and validation accuracy for resnet transfer learning model 
plt.figure(figsize=(10,10))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('resnet_chest_accuracy.png')
plt.show()

#Plot for model loss and validation loss for resnet transfer learning model 
plt.figure(figsize=(10,10))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('resnet_chest_loss.png')
plt.show()

"""##**Xception Transfer Learning Model**"""

#Building the xception transfer learning model 
xception = Xception(weights="imagenet", include_top=False,
    input_tensor=Input(shape=(224, 224, 3)))

outputs = xception.output
outputs = Flatten(name="flatten")(outputs)
outputs = Dropout(0.5)(outputs)
outputs = Dense(2, activation="softmax")(outputs)

model1 = Model(inputs=xception.input, outputs=outputs)

for layer in xception.layers:
    layer.trainable = False # As we are using the transfer learning weights and not traning our model, the trainable parameter is False

model1.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])

model1.summary()

#Fitting the model on augmented x_train data
history = model1.fit(train_aug.flow(X_train, y_train, batch_size=32),
                    validation_data=(X_test, y_test),
                    validation_steps=len(X_test) / 32,
                    steps_per_epoch=len(X_train) / 32,
                    epochs=20)

#Saving the model and weights for future use
model1.save('xception_chest.h5')

model1.save_weights('xceptionweights_chest.hdf5')

model1 = load_model('xception_chest.h5')
#Predicting the labels for testing images
y_pred = model1.predict(X_test, batch_size= 32)

#Predicitng the outcomes using a threshold of 0.5
prediction=y_pred[0:10]
for index, probability in enumerate(prediction):
  if probability[1] > 0.5:
        plt.title('%.2f' % (probability[1]*100) + '% COVID')
  else:
        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')
  plt.imshow(X_test[index])
  plt.show()

# Convert to Binary classes as the target labels were converted to_categorical form
y_pred_bin = np.argmax(y_pred, axis=1)
y_test_bin = np.argmax(y_test, axis=1)

#Plotting the ROC curve for the predicted values for model evaluation
fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)
plt.plot(fpr, tpr)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.rcParams['font.size'] = 12
plt.title('ROC curve for our model1')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)

#defining a fucntion to generate a heatmap confusion matrix for predicted values 
def plot_confusion_matrix(normalize):
  classes = ['COVID','NonCOVID']
  tick_marks = [0.5,1.5]
  cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)
  sns.heatmap(cn,cmap='plasma',annot=True)
  plt.xticks(tick_marks, classes)
  plt.yticks(tick_marks, classes)
  plt.title('Confusion Matrix')
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()
  
#Plotting the confusion matrix with normalized and non-normalized outputs
print('Confusion Matrix without Normalization')
plot_confusion_matrix(normalize=None)

print('Confusion Matrix with Normalized Values')
plot_confusion_matrix(normalize='true')

#Printing the classification report 
print(classification_report(y_test_bin, y_pred_bin))

#Plot for model accuracy and validation accuracy for xception transfer learning model 

plt.figure(figsize=(10,10))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('xception_chest_accuracy.png')
plt.show()

#Plot for model loss and validation loss for xception transfer learning model 

plt.figure(figsize=(10,10))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('xception_chest_loss.png')
plt.show()

#Building the VGG19 transfer learning model 
vggModel = VGG19(weights="imagenet", include_top=False,
    input_tensor=Input(shape=(224, 224, 3)))

outputs = vggModel.output
outputs = Flatten(name="flatten")(outputs)
outputs = Dropout(0.5)(outputs)
outputs = Dense(2, activation="softmax")(outputs)

model2 = Model(inputs=vggModel.input, outputs=outputs)

for layer in vggModel.layers:
    layer.trainable = False # As we are using the transfer learning weights and not traning our model, the trainable parameter is False

model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model2.summary()

#Fitting the model on augmented x_train data
history = model2.fit(train_aug.flow(X_train, y_train, batch_size=32),
                    validation_data=(X_test, y_test),
                    validation_steps=len(X_test) / 32,
                    steps_per_epoch=len(X_train) / 32,
                    epochs=20)

#Saving the model and weights for future use
model2.save('vgg_chest.h5')
model2.save_weights('vggweights_chest.hdf5')

model2 = load_model('vgg_chest.h5')
#Predicting the labels for testing images
y_pred = model2.predict(X_test, batch_size= 32)

#Predicitng the outcomes using a threshold of 0.5
prediction=y_pred[0:10]
for index, probability in enumerate(prediction):
  if probability[1] > 0.5:
        plt.title('%.2f' % (probability[1]*100) + '% COVID')
  else:
        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')
  plt.imshow(X_test[index])
  plt.show()

# Convert to Binary classes as the target labels were converted to_categorical form
y_pred_bin = np.argmax(y_pred, axis=1)
y_test_bin = np.argmax(y_test, axis=1)

#Plotting the ROC curve for the predicted values for model evaluation
fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)
plt.plot(fpr, tpr)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.rcParams['font.size'] = 12
plt.title('ROC curve for our model')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)

#defining a fucntion to generate a heatmap confusion matrix for predicted values 
def plot_confusion_matrix(normalize):
  classes = ['COVID','NonCOVID']
  tick_marks = [0.5,1.5]
  cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)
  sns.heatmap(cn,cmap='plasma',annot=True)
  plt.xticks(tick_marks, classes)
  plt.yticks(tick_marks, classes)
  plt.title('Confusion Matrix')
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()

#Plotting the confusion matrix with normalized and non-normalized outputs
print('Confusion Matrix without Normalization')
plot_confusion_matrix(normalize=None)

print('Confusion Matrix with Normalized Values')
plot_confusion_matrix(normalize='true')

#Printing the classification report 
print(classification_report(y_test_bin, y_pred_bin))

#Plot for model accuracy and validation accuracy for VGG19 transfer learning model 
plt.figure(figsize=(10,10))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('vgg_chest_accuracy.png')
plt.show()

#Plot for model loss and validation loss for VGG19 transfer learning model 
plt.figure(figsize=(10,10))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.legend(['Training', 'Testing'])
plt.savefig('vgg_chest_loss.png')
plt.show()

"""## **Xception model outperformed the other two models**"""